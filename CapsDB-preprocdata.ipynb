{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Helix Capping Residues #\n",
    "\n",
    "The goal is to identify residues just before an alpha helix begins or the residues just after the helix ends. This will improve secondary structure predictors becuase they often extend too far or do not start at the right place. \n",
    "\n",
    "The CapsDB has annoted sequences of structures of helix capping residues that can be used to train a deep nueral net. We will use a Bidirectional LSTM using phi/psi features to see if it will those will be good predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Features ##\n",
    "### MMTF Pyspark Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from mmtfPyspark.io import mmtfReader\n",
    "from mmtfPyspark.webfilters import Pisces\n",
    "from mmtfPyspark.filters import ContainsLProteinChain\n",
    "from mmtfPyspark.mappers import StructureToPolymerChains\n",
    "from mmtfPyspark.ml import ProteinSequenceEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secondaryStructureExtractorFull\n",
    "#import mmtfToASA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Spark Context ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[8]\").appName(\"DeepCap\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SQLContext ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import concat, col, lit, array_contains\n",
    "\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in filtered cap+MMTF data from parquet file###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read output of above get_dataset operation from parquet file\n",
    "parquetPath = '/home/ec2-user/SageMaker/ProteinFragmenter/datacaps.parquet'\n",
    "dataframe = sqlContext.read.parquet(parquetPath)\n",
    "data = dataframe.toPandas()\n",
    "data = data.drop('__index_level_0__', axis=1)\n",
    "\n",
    "capsdb = sqlContext.read.parquet('caps_descriptors.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Torsion angle and secondary structure info ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbId</th>\n",
       "      <th>chain</th>\n",
       "      <th>resi</th>\n",
       "      <th>resn</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>THR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.677383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>GLY</td>\n",
       "      <td>-66.660973</td>\n",
       "      <td>160.703186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>SER</td>\n",
       "      <td>-123.853607</td>\n",
       "      <td>-7.871733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>LEU</td>\n",
       "      <td>-74.896896</td>\n",
       "      <td>137.483932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>TYR</td>\n",
       "      <td>-134.419830</td>\n",
       "      <td>140.864288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "      <td>LEU</td>\n",
       "      <td>-139.275024</td>\n",
       "      <td>127.621544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "      <td>TRP</td>\n",
       "      <td>-152.167755</td>\n",
       "      <td>166.833832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>ILE</td>\n",
       "      <td>-108.079048</td>\n",
       "      <td>119.799377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>ASP</td>\n",
       "      <td>-61.786110</td>\n",
       "      <td>150.193756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>ALA</td>\n",
       "      <td>-47.469296</td>\n",
       "      <td>-38.584801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdbId chain  resi resn         phi         psi\n",
       "0  2ygn     A     1  THR         NaN  163.677383\n",
       "1  2ygn     A     2  GLY  -66.660973  160.703186\n",
       "2  2ygn     A     3  SER -123.853607   -7.871733\n",
       "3  2ygn     A     4  LEU  -74.896896  137.483932\n",
       "4  2ygn     A     5  TYR -134.419830  140.864288\n",
       "5  2ygn     A     6  LEU -139.275024  127.621544\n",
       "6  2ygn     A     7  TRP -152.167755  166.833832\n",
       "7  2ygn     A     8  ILE -108.079048  119.799377\n",
       "8  2ygn     A     9  ASP  -61.786110  150.193756\n",
       "9  2ygn     A    10  ALA  -47.469296  -38.584801"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = capsdb.toPandas()\n",
    "df = pd.merge(data, df1, left_on=('pdbId','chain'), right_on=('pdbid','chain'), how='inner')\n",
    "df = df[['pdbId', 'chain', 'resi', 'resn', 'phi', 'psi', 'startcap', 'endcap']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_cap'] = df.apply(lambda x: 1 if (x['resi'] >= x['startcap'] and x['resi'] <= x['endcap']) else 0, axis=1)\n",
    "df_caps = df.groupby([\"pdbId\", \"chain\", \"resi\"])['is_cap'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caps = pd.merge(data, df_caps, left_on=('pdbId','chain', 'resi'), right_on=('pdbId','chain', 'resi'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbId</th>\n",
       "      <th>chain</th>\n",
       "      <th>resi</th>\n",
       "      <th>resn</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "      <th>is_cap</th>\n",
       "      <th>ALA</th>\n",
       "      <th>CYS</th>\n",
       "      <th>ASP</th>\n",
       "      <th>...</th>\n",
       "      <th>MET</th>\n",
       "      <th>ASN</th>\n",
       "      <th>PRO</th>\n",
       "      <th>GLN</th>\n",
       "      <th>ARG</th>\n",
       "      <th>SER</th>\n",
       "      <th>THR</th>\n",
       "      <th>VAL</th>\n",
       "      <th>TRP</th>\n",
       "      <th>TYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>THR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.677383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>GLY</td>\n",
       "      <td>-66.660973</td>\n",
       "      <td>160.703186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>SER</td>\n",
       "      <td>-123.853607</td>\n",
       "      <td>-7.871733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>LEU</td>\n",
       "      <td>-74.896896</td>\n",
       "      <td>137.483932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ygn</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>TYR</td>\n",
       "      <td>-134.419830</td>\n",
       "      <td>140.864288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdbId chain  resi resn         phi         psi  is_cap  ALA  CYS  ASP ...   \\\n",
       "0  2ygn     A     1  THR         NaN  163.677383       0    0    0    0 ...    \n",
       "1  2ygn     A     2  GLY  -66.660973  160.703186       0    0    0    0 ...    \n",
       "2  2ygn     A     3  SER -123.853607   -7.871733       0    0    0    0 ...    \n",
       "3  2ygn     A     4  LEU  -74.896896  137.483932       0    0    0    0 ...    \n",
       "4  2ygn     A     5  TYR -134.419830  140.864288       0    0    0    0 ...    \n",
       "\n",
       "   MET  ASN  PRO  GLN  ARG  SER  THR  VAL  TRP  TYR  \n",
       "0    0    0    0    0    0    0    1    0    0    0  \n",
       "1    0    0    0    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    1    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0    0    0    1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio.PDB.Polypeptide import aa3\n",
    "one_hot_encoded = pd.DataFrame(data_caps.resn.apply(lambda x: secondaryStructureExtractorFull.get_residue(x)).tolist(), columns=aa3)\n",
    "one_hot_encoded.head()\n",
    "data_caps = data_caps.join(one_hot_encoded)\n",
    "data_caps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_cap(pdbId, chain, resi, is_cap):\n",
    "    if is_cap == 1:\n",
    "        return(1)\n",
    "    elif is_cap == 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        raise ValueError(\"is_cap must be 0 or 1\")\n",
    "\n",
    "def angle_to_cos(angle):\n",
    "    if(angle == 0 or np.isnan(angle)):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.cos(np.pi * angle/180)\n",
    "\n",
    "def angle_to_sin(angle):\n",
    "    if(angle == 0 or np.isnan(angle)):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sin(np.pi * angle/180)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data into list of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n"
     ]
    }
   ],
   "source": [
    "groups = data_caps.groupby([\"pdbId\", \"chain\"])\n",
    "                           # num pdbs,    max len of seqs, num features\n",
    "\n",
    "# Check max length of protein chains\n",
    "# maxlen = 0\n",
    "# for i, ((pdbid, chain), group) in enumerate(groups):\n",
    "#     l = 0\n",
    "#     for j, featuretuple in enumerate(group.itertuples()):\n",
    "#         l += 1\n",
    "#         if l > maxlen:\n",
    "#             maxlen = l\n",
    "# print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chains = []\n",
    "label_chains = []\n",
    "laglabel_chains = []\n",
    "\n",
    "for i, ((pdbid, chain), group) in enumerate(groups):\n",
    "    # Create empty arrays\n",
    "    train_chain = np.zeros((1300,24), dtype=float) # max chain length is 1288 residues\n",
    "    label_chain = np.zeros((1300,1), dtype=int)\n",
    "    laglabel_chain = np.zeros((5000,1), dtype=int)\n",
    "    \n",
    "    # Populate arrays\n",
    "    for j, featuretuple in enumerate(group.itertuples()):\n",
    "        train_chain[j, :] = (angle_to_cos(featuretuple.phi), angle_to_sin(featuretuple.phi), \n",
    "                              angle_to_cos(featuretuple.psi), angle_to_sin(featuretuple.psi), featuretuple.ALA,\n",
    "                              featuretuple.CYS,featuretuple.ASP,featuretuple.GLU,featuretuple.PHE,\n",
    "                              featuretuple.GLY,featuretuple.HIS,featuretuple.ILE,featuretuple.LYS,\n",
    "                              featuretuple.LEU,featuretuple.MET,featuretuple.ASN,featuretuple.PRO,\n",
    "                              featuretuple.GLN,featuretuple.ARG,featuretuple.SER,featuretuple.THR,\n",
    "                              featuretuple.VAL,featuretuple.TRP,featuretuple.TYR)\n",
    "        label_chain[j,0] = is_cap(featuretuple.pdbId, featuretuple.chain, featuretuple.resi, featuretuple.is_cap)\n",
    "        if (j > 0):\n",
    "            laglabel_chain[j-1,0] = label_chain[j,0]\n",
    "    \n",
    "    # Trim zeros\n",
    "    trimmed_train = train_chain[~np.all(train_chain == 0, axis=1)]\n",
    "    trimmed_label = label_chain[:trimmed_train.shape[0]]\n",
    "    trimmed_laglabel = label_chain[:trimmed_train.shape[0]+1]\n",
    "    \n",
    "    # Add chain data to lists of arrays\n",
    "    train_chains.append(trimmed_train)\n",
    "    label_chains.append(trimmed_label)\n",
    "    laglabel_chains.append(trimmed_laglabel)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write training data to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"pickled_data/train_chains.pickle\",\"wb\")\n",
    "pickle.dump(train_chains, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickled_data/label_chains.pickle\",\"wb\")\n",
    "pickle.dump(label_chains, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickled_data/laglabel_chains.pickle\",\"wb\")\n",
    "pickle.dump(laglabel_chains, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below reads in 1-dim (binary) labels and writes back out as 2-dim labels (one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "label_chain_in = open(\"pickled_data/label_chains.pickle\",\"rb\")\n",
    "labels = pickle.load(label_chain_in)\n",
    "\n",
    "newlabels = []\n",
    "for i, l in enumerate(labels):\n",
    "    temp = np.zeros([l.shape[0], 2], dtype=int)\n",
    "    temp[:,1] = l[:,0]\n",
    "    temp[:,0] = (l[:,0]+1)%2\n",
    "    newlabels.append(temp)\n",
    "\n",
    "pickle_out = open(\"pickled_data/label_chains.pickle\",\"wb\")\n",
    "pickle.dump(newlabels, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "laglabel_chain_in = open(\"pickled_data/laglabel_chains.pickle\",\"rb\")\n",
    "labelslag = pickle.load(laglabel_chain_in)\n",
    "\n",
    "newlabelslag = []\n",
    "for i, l in enumerate(labelslag):\n",
    "    temp = np.zeros([l.shape[0], 2], dtype=int)\n",
    "    temp[:,1] = l[:,0]\n",
    "    temp[:,0] = (l[:,0]+1)%2\n",
    "    newlabelslag.append(temp)\n",
    "\n",
    "pickle_out = open(\"pickled_data/laglabel_chains.pickle\",\"wb\")\n",
    "pickle.dump(newlabelslag, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below reads in train/label and writes out lists sorted by chain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_chain_in = open(\"pickled_data/train_chains.pickle\",\"rb\")\n",
    "train = pickle.load(train_chain_in)\n",
    "\n",
    "lens = [len(chain) for chain in train]\n",
    "inds = range(len(train))\n",
    "lenSeries = pd.Series(data=lens, index=inds).sort_values()\n",
    "newInds = lenSeries.index.values\n",
    "newlist = []\n",
    "[newlist.append(train[i]) for i in newInds]\n",
    "\n",
    "pickle_out = open(\"pickled_data/train_chains_sorted.pickle\",\"wb\")\n",
    "pickle.dump(newlist, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# now sort label list\n",
    "label_chain_in = open(\"pickled_data/label_chains.pickle\",\"rb\")\n",
    "labels = pickle.load(label_chain_in)\n",
    "\n",
    "newlist2 = []\n",
    "[newlist2.append(labels[i]) for i in newInds]\n",
    "\n",
    "pickle_out = open(\"pickled_data/label_chains_sorted.pickle\",\"wb\")\n",
    "pickle.dump(newlist2, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# now sort laglabel list\n",
    "laglabel_chain_in = open(\"pickled_data/laglabel_chains.pickle\",\"rb\")\n",
    "labelslag = pickle.load(laglabel_chain_in)\n",
    "\n",
    "newlist3 = []\n",
    "[newlist3.append(labelslag[i]) for i in newInds]\n",
    "\n",
    "pickle_out = open(\"pickled_data/laglabel_chains_sorted.pickle\",\"wb\")\n",
    "pickle.dump(newlist3, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mybinder-environment",
   "language": "python",
   "name": "conda_mybinder-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
