{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Helix Capping Residues #\n",
    "\n",
    "The goal is to identify residues just before an alpha helix begins or the residues just after the helix ends. This will improve secondary structure predictors becuase they often extend too far or do not start at the right place. \n",
    "\n",
    "The CapsDB has annoted sequences of structures of helix capping residues that can be used to train a deep nueral net. We will use a Bidirectional LSTM using phi/psi features to see if it will those will be good predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build generator for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, batch_size=1, num_features=24, shuffle=True):\n",
    "        'Initialization'\n",
    "        \n",
    "        data_chain_in = open(\"pickled_data/train_chains.pickle\",\"rb\")\n",
    "        self.train_data = pickle.load(data_chain_in)\n",
    "        label_chain_in = open(\"pickled_data/label_chains.pickle\",\"rb\")\n",
    "        self.labels = pickle.load(label_chain_in)\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.dim = [None,num_features]\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = np.arange(len(self.labels)) # length of training set size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim)\n",
    "        # Initialization\n",
    "        \n",
    "        # hardcode in sizes to test instead of using \"*self.dim\"\n",
    "        \n",
    "        residues = len(self.labels[list_IDs_temp[0]]) # this only works for batch_size=1\n",
    "        \n",
    "        X = np.empty((self.batch_size, residues, self.num_features))\n",
    "        y = np.empty((self.batch_size, residues, 1), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = self.train_data[ID]\n",
    "#             print(ID)\n",
    "#             print(y.shape)\n",
    "#             print(self.labels[ID].shape)\n",
    "            \n",
    "            y[i,] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "from keras.layers import *# Input, Dense, Bidirectional, LSTM, Concatenate, CuDNNLSTM, Masking\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(batch_size, num_features):\n",
    "\n",
    "    #Xchain = tf.placeholder(tf.float32, [None, batch_size, num_features], name='InputSequence')\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(Input(shape=(None, num_features), name=\"input\"))\n",
    "    model.add(Bidirectional(CuDNNLSTM(units=100, # dimensionality of the output space, independent of # timesteps\n",
    "                        input_shape=(None, num_features),\n",
    "                        return_sequences=True)))\n",
    "    # model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    # if use_dropout:\n",
    "    #     model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.add(Activation('softmax'))\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "num_features=24\n",
    "\n",
    "model = create_model(batch_size, num_features)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6714/6714 [==============================] - 178s 26ms/step - loss: 13.9078 - acc: 0.1276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc82fed9b0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate generator\n",
    "training_generator = DataGenerator()\n",
    "\n",
    "model.fit_generator(generator=training_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00854491, -0.0161927 , -0.0601163 , ..., -0.09773389,\n",
       "         -0.11893874,  0.0553289 ],\n",
       "        [-0.10674282, -0.07672422,  0.09192923, ...,  0.06227181,\n",
       "         -0.03067157, -0.03693574],\n",
       "        [ 0.04261782,  0.05634183, -0.11564188, ...,  0.10435071,\n",
       "         -0.00097653,  0.09903456],\n",
       "        ...,\n",
       "        [-0.05936329,  0.10208074,  0.08211298, ...,  0.02234525,\n",
       "          0.07386395,  0.01436683],\n",
       "        [-0.05875681, -0.04208422, -0.04683439, ...,  0.07434059,\n",
       "         -0.03841694,  0.00487308],\n",
       "        [-0.07576571, -0.09590036, -0.06673967, ...,  0.01174287,\n",
       "         -0.01837976, -0.11706314]], dtype=float32),\n",
       " array([[-0.005871  ,  0.01902355, -0.01430513, ...,  0.01031065,\n",
       "         -0.01314655, -0.00064888],\n",
       "        [-0.00135805,  0.02088111,  0.01959058, ..., -0.05063406,\n",
       "         -0.00305159, -0.01162037],\n",
       "        [-0.01150192,  0.00695272,  0.00809403, ...,  0.10554451,\n",
       "         -0.07422917, -0.011684  ],\n",
       "        ...,\n",
       "        [ 0.00197234, -0.05778326,  0.04535292, ...,  0.01656652,\n",
       "          0.08314546,  0.00517645],\n",
       "        [-0.01984993, -0.0432022 , -0.00700021, ...,  0.04245329,\n",
       "         -0.05756681,  0.01625143],\n",
       "        [ 0.04176682, -0.03631207,  0.00485236, ..., -0.04546823,\n",
       "         -0.08728718,  0.03246204]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[ 0.18203887],\n",
       "        [-0.16689253],\n",
       "        [ 0.05861589],\n",
       "        [ 0.0679267 ],\n",
       "        [ 0.13967621],\n",
       "        [ 0.1478965 ],\n",
       "        [ 0.09942588],\n",
       "        [-0.1493887 ],\n",
       "        [ 0.01050824],\n",
       "        [ 0.23010543],\n",
       "        [-0.08609864],\n",
       "        [ 0.23966676],\n",
       "        [ 0.18237227],\n",
       "        [-0.04568094],\n",
       "        [-0.23513857],\n",
       "        [ 0.17246243],\n",
       "        [ 0.15671527],\n",
       "        [ 0.05451792],\n",
       "        [-0.16648501],\n",
       "        [ 0.15016529],\n",
       "        [-0.23197816],\n",
       "        [ 0.01272884],\n",
       "        [-0.12970892],\n",
       "        [-0.22021548],\n",
       "        [ 0.07227442],\n",
       "        [-0.13888389],\n",
       "        [ 0.125857  ],\n",
       "        [ 0.14065218],\n",
       "        [-0.08149953],\n",
       "        [-0.2398472 ],\n",
       "        [ 0.16251507],\n",
       "        [ 0.19193947],\n",
       "        [ 0.21271816],\n",
       "        [ 0.17309391],\n",
       "        [ 0.08337057],\n",
       "        [-0.21588932],\n",
       "        [ 0.09550163],\n",
       "        [-0.01566103],\n",
       "        [-0.21898527],\n",
       "        [-0.19388443],\n",
       "        [ 0.03647316],\n",
       "        [-0.01256438],\n",
       "        [ 0.1740979 ],\n",
       "        [ 0.21519536],\n",
       "        [-0.16964605],\n",
       "        [-0.16629934],\n",
       "        [-0.08620834],\n",
       "        [ 0.15652236],\n",
       "        [-0.20046039],\n",
       "        [-0.090005  ],\n",
       "        [ 0.16975111],\n",
       "        [-0.10002105],\n",
       "        [ 0.10568196],\n",
       "        [-0.05785313],\n",
       "        [-0.08699074],\n",
       "        [ 0.18780258],\n",
       "        [ 0.05064139],\n",
       "        [ 0.1789313 ],\n",
       "        [-0.08089902],\n",
       "        [-0.19925112],\n",
       "        [ 0.04611909],\n",
       "        [ 0.05982336],\n",
       "        [-0.08282335],\n",
       "        [-0.21915339],\n",
       "        [ 0.17748627],\n",
       "        [-0.19686201],\n",
       "        [ 0.2176005 ],\n",
       "        [ 0.16305909],\n",
       "        [-0.12592244],\n",
       "        [-0.05807848],\n",
       "        [ 0.138289  ],\n",
       "        [-0.23508155],\n",
       "        [-0.1986728 ],\n",
       "        [ 0.01190132],\n",
       "        [ 0.06185985],\n",
       "        [-0.09389754],\n",
       "        [-0.17477895],\n",
       "        [ 0.01101467],\n",
       "        [ 0.17835811],\n",
       "        [-0.21435055],\n",
       "        [ 0.22894618],\n",
       "        [-0.05218956],\n",
       "        [ 0.05500692],\n",
       "        [ 0.22173879],\n",
       "        [ 0.20535311],\n",
       "        [ 0.10397369],\n",
       "        [-0.19892006],\n",
       "        [-0.11581226],\n",
       "        [-0.09775108],\n",
       "        [-0.22024547],\n",
       "        [ 0.15272453],\n",
       "        [-0.1612149 ],\n",
       "        [-0.23228668],\n",
       "        [-0.17632353],\n",
       "        [-0.16738898],\n",
       "        [ 0.18633401],\n",
       "        [ 0.08254406],\n",
       "        [-0.02215987],\n",
       "        [-0.02668861],\n",
       "        [-0.20188236]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mybinder-environment",
   "language": "python",
   "name": "conda_mybinder-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
